#!/usr/bin/env python3
"""
ì¹´ì¹´ì˜¤í†¡ í…œí”Œë¦¿ ìë™ ìƒì„± API
ìœ ì‚¬ë„ ê²€ìƒ‰ì„ í†µí•´ ê¸°ì¡´ ìŠ¹ì¸ í…œí”Œë¦¿ ì°¸ê³  ë˜ëŠ” ìƒˆë¡œìš´ í…œí”Œë¦¿ ìƒì„±
"""

import os
import json
import logging
from typing import Dict, List, Any, Optional, Tuple
import chromadb
from chromadb.config import Settings
from chromadb.utils import embedding_functions
from dotenv import load_dotenv
import openai
from fastapi import FastAPI, HTTPException
from pydantic import BaseModel

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s | %(name)s | %(levelname)s | %(message)s',
    datefmt='%H:%M:%S'
)

logger = logging.getLogger(__name__)
from templateEngine.prompts.message_analyzer_prompts import (
    ReferenceBasedTemplatePromptBuilder,
    PolicyGuidedTemplatePromptBuilder,
    NewTemplatePromptBuilder,
    TemplateTitlePromptBuilder
)

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# OpenAI API ì„¤ì •
openai.api_key = os.getenv('OPENAI_API_KEY')

class TemplateRequest(BaseModel):
    """í…œí”Œë¦¿ ìƒì„± ìš”ì²­ ëª¨ë¸"""
    category_main: str                    # ì¹´í…Œê³ ë¦¬ ëŒ€ë¶„ë¥˜
    category_sub: str                     # ì¹´í…Œê³ ë¦¬ ì†Œë¶„ë¥˜
    type: str                            # ë©”ì‹œì§€ ìœ í˜•: "BASIC" | "EXTRA_INFO" | "CHANNEL_ADD" | "HYBRID"
    has_channel_link: bool               # ì±„ë„ ë§í¬ ì—¬ë¶€
    has_extra_info: bool                 # ë¶€ê°€ ì„¤ëª… ì—¬ë¶€
    label: Optional[str] = None          # ë¼ë²¨
    use_case: Optional[str] = None
    intent_type: Optional[str] = None
    recipient_scope: Optional[str] = None
    links_allowed: bool = True
    variables: List[str] = []
    section_path: List[str] = []
    source: Optional[str] = None
    source_tag: Optional[str] = None
    user_text: str                       # ì›ë³¸ ì‚¬ìš©ì ë©”ì‹œì§€ (ìœ ì‚¬ë„ ê²€ìƒ‰ìš©)

class TemplateResponse(BaseModel):
    """í…œí”Œë¦¿ ìƒì„± ì‘ë‹µ ëª¨ë¸"""
    template_text: str
    template_title: str
    generation_method: str  # "reference_based", "new_creation"
    reference_template_id: Optional[str] = None
    metadata: Dict[str, Any]

class TemplateGenerator:
    def __init__(self):
        self.client = None
        self.openai_api_key = os.getenv('OPENAI_API_KEY')
        self.connect_to_chroma()
    
    def connect_to_chroma(self):
        """ChromaDB ì—°ê²°"""
        chroma_host = os.getenv('CHROMA_HOST', 'localhost')
        chroma_port = int(os.getenv('CHROMA_PORT', '8000'))
        chroma_persist_dir = os.getenv('CHROMA_PERSIST_DIR', './chroma_db')
        
        logger.info("ğŸ”— ChromaDB ì—°ê²° ì‹œë„ ì¤‘...")
        logger.debug(f"[CONFIG] host: {chroma_host}, port: {chroma_port}, persist_dir: {chroma_persist_dir}")
        
        try:
            # HTTP í´ë¼ì´ì–¸íŠ¸ë¡œ ì—°ê²° ì‹œë„
            logger.debug("ğŸŒ HTTP í´ë¼ì´ì–¸íŠ¸ë¡œ ì—°ê²° ì‹œë„...")
            self.client = chromadb.HttpClient(
                host=chroma_host,
                port=chroma_port
            )
            self.client.heartbeat()
            logger.info(f"âœ… ChromaDB HTTP ì—°ê²° ì„±ê³µ: {chroma_host}:{chroma_port}")
        except Exception as e:
            logger.warning(f"âš ï¸ HTTP ì—°ê²° ì‹¤íŒ¨: {e}")
            try:
                # ë¡œì»¬ PersistentClientë¡œ ì—°ê²° ì‹œë„
                logger.debug("ğŸ’¾ ë¡œì»¬ PersistentClientë¡œ ì—°ê²° ì‹œë„...")
                self.client = chromadb.PersistentClient(
                    path=chroma_persist_dir,
                    settings=Settings(anonymized_telemetry=False)
                )
                logger.info(f"âœ… ë¡œì»¬ ChromaDB ì—°ê²° ì„±ê³µ: {chroma_persist_dir}")
            except Exception as e2:
                logger.error(f"âŒ ChromaDB ì—°ê²° ì™„ì „ ì‹¤íŒ¨: {e2}")
                raise Exception("ChromaDB ì—°ê²°ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
    
    def search_similar_templates(self, query_text: str, category_main: str, category_sub: str, top_k: int = 3, select_count: int = 2) -> Tuple[List[Dict], float]:
        """
        ìŠ¹ì¸ëœ í…œí”Œë¦¿ì—ì„œ ìœ ì‚¬ë„ ê²€ìƒ‰ (ìš”êµ¬ì‚¬í•­ì— ë§ê²Œ ìˆ˜ì •)
        - 1ì°¨Â·2ì°¨ ì¹´í…Œê³ ë¦¬ ë©”íƒ€ë°ì´í„°ë¡œ í•„í„°ë§
        - Top 3 ê²€ìƒ‰ í›„ 2ê°œ ì„ íƒ
        """
        logger.info("ğŸ” ìœ ì‚¬ í…œí”Œë¦¿ ê²€ìƒ‰ ì‹œì‘")
        logger.debug(f"[INPUT] query_text ê¸¸ì´: {len(query_text)}, category: {category_main} > {category_sub}")
        logger.debug(f"[PARAMS] top_k: {top_k}, select_count: {select_count}")
        
        try:
            # approved ì»¬ë ‰ì…˜ ê°€ì ¸ì˜¤ê¸°
            logger.debug("ğŸ“š 'approved' ì»¬ë ‰ì…˜ ê°€ì ¸ì˜¤ëŠ” ì¤‘...")
            collection = self.client.get_collection('approved')
            
            # ì¹´í…Œê³ ë¦¬ í•„í„°ë§ì„ ìœ„í•œ where ì¡°ê±´ êµ¬ì„±
            where_filter = {}
            if category_main:
                where_filter['category_main'] = category_main
            if category_sub:
                where_filter['category_sub'] = category_sub
            
            logger.debug(f"ğŸ” í•„í„° ì¡°ê±´: {where_filter}")
            
            # ìœ ì‚¬ë„ ê²€ìƒ‰ ìˆ˜í–‰ (ìƒìœ„ 3ê°œ)
            logger.debug(f"ğŸ” ChromaDBì—ì„œ {top_k}ê°œ ê²€ìƒ‰ ì¤‘...")
            results = collection.query(
                query_texts=[query_text],
                n_results=top_k,
                where=where_filter if where_filter else None,
                include=['documents', 'metadatas', 'distances']
            )
            
            similar_templates = []
            max_similarity = 0.0
            
            if results and results['documents'] and results['documents'][0]:
                logger.info(f"ğŸ“Š ê²€ìƒ‰ ê²°ê³¼: {len(results['documents'][0])}ê°œ í…œí”Œë¦¿ ë°œê²¬")
                
                for i, (doc, metadata, distance) in enumerate(zip(
                    results['documents'][0],
                    results['metadatas'][0], 
                    results['distances'][0]
                )):
                    # ê±°ë¦¬ë¥¼ ìœ ì‚¬ë„ë¡œ ë³€í™˜ (ê±°ë¦¬ê°€ ì‘ì„ìˆ˜ë¡ ìœ ì‚¬ë„ ë†’ìŒ)
                    similarity = 1.0 - distance
                    max_similarity = max(max_similarity, similarity)
                    
                    template_info = {
                        'id': results['ids'][0][i],
                        'text': doc,
                        'metadata': metadata,
                        'similarity': similarity,
                        'rank': i + 1
                    }
                    similar_templates.append(template_info)
                    logger.debug(f"ğŸ“„ í…œí”Œë¦¿ {i+1}: ìœ ì‚¬ë„ {similarity:.3f}, ID: {results['ids'][0][i]}")
            else:
                logger.warning("âš ï¸ ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤")
            
            # ìœ ì‚¬ë„ ìˆœìœ¼ë¡œ ì •ë ¬
            similar_templates.sort(key=lambda x: x['similarity'], reverse=True)
            
            # ìš”êµ¬ì‚¬í•­: Top 3 ì¤‘ 2ê°œ ì„ íƒ
            selected_templates = similar_templates[:select_count]
            
            logger.info(f"âœ… RAG ê²€ìƒ‰ ì™„ë£Œ: {len(similar_templates)}ê°œ ì¤‘ {len(selected_templates)}ê°œ ì„ íƒ (ìµœëŒ€ ìœ ì‚¬ë„: {max_similarity:.3f})")
            
            return selected_templates, max_similarity
            
        except Exception as e:
            logger.error(f"âŒ ìœ ì‚¬ë„ ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
            return [], 0.0
    
    def generate_template_with_reference(self, request: TemplateRequest, reference_templates: List[Dict]) -> str:
        """ì°¸ê³  í…œí”Œë¦¿ 2ê°œë¥¼ ê¸°ë°˜ìœ¼ë¡œ ìƒˆ í…œí”Œë¦¿ ìƒì„± (ìš”êµ¬ì‚¬í•­ì— ë§ê²Œ ìˆ˜ì •)"""
        logger.info("ğŸ“ ì°¸ê³  í…œí”Œë¦¿ ê¸°ë°˜ ìƒì„± ì‹œì‘")
        logger.debug(f"[INPUT] ì°¸ê³  í…œí”Œë¦¿ {len(reference_templates)}ê°œ, ì¹´í…Œê³ ë¦¬: {request.category_main} > {request.category_sub}")
        
        try:
            # ì°¸ê³  í…œí”Œë¦¿ë“¤ì„ ì»¨í…ìŠ¤íŠ¸ë¡œ êµ¬ì„±
            reference_context = "\n\n".join([
                f"ì°¸ê³  í…œí”Œë¦¿ {i+1}:\n{template['text']}"
                for i, template in enumerate(reference_templates)
            ])
            logger.debug(f"ğŸ“š ì°¸ê³  ì»¨í…ìŠ¤íŠ¸ êµ¬ì„± ì™„ë£Œ: {len(reference_context)}ì")
            
            prompt = f"""
ë‹¤ìŒì€ ìŠ¹ì¸ë°›ì€ ì¹´ì¹´ì˜¤í†¡ ì•Œë¦¼í†¡ í…œí”Œë¦¿ë“¤ì…ë‹ˆë‹¤:

=== ì°¸ê³  í…œí”Œë¦¿ë“¤ ===
{reference_context}

=== ìƒˆ í…œí”Œë¦¿ ìƒì„± ìš”ì²­ ===
ì‚¬ìš©ì ì…ë ¥: {request.user_text}
1ì°¨ ì¹´í…Œê³ ë¦¬: {request.category_main}
2ì°¨ ì¹´í…Œê³ ë¦¬: {request.category_sub}
ë©”ì‹œì§€ ìœ í˜•: {request.type}
ì±„ë„ ë§í¬ ì—¬ë¶€: {request.has_channel_link}
ë¶€ê°€ ì •ë³´ ì—¬ë¶€: {request.has_extra_info}
ë¼ë²¨: {request.label}
ì‚¬ìš© ì‚¬ë¡€: {request.use_case}
ì˜ë„ ìœ í˜•: {request.intent_type}
ìˆ˜ì‹ ì ë²”ìœ„: {request.recipient_scope}

ìœ„ ì°¸ê³  í…œí”Œë¦¿ë“¤ì˜ êµ¬ì¡°ì™€ ìŠ¤íƒ€ì¼ì„ ì°¸ê³ í•˜ì—¬, ì‚¬ìš©ì ì…ë ¥ì— ë§ëŠ” ìƒˆë¡œìš´ ì¹´ì¹´ì˜¤í†¡ ì•Œë¦¼í†¡ í…œí”Œë¦¿ì„ ìƒì„±í•´ì£¼ì„¸ìš”.

ì¤‘ìš” ê·œì¹™:
1. ë³€ìˆ˜ëŠ” #{{ë³€ìˆ˜ëª…}} í˜•íƒœë¡œ í‘œí˜„
2. ê´‘ê³ ì„± ë‚´ìš© ê¸ˆì§€, ì •ë³´ì„±/ì•ˆë‚´ì„± ë‚´ìš©ë§Œ í¬í•¨
3. ë°œì†¡ ê·¼ê±°ë¥¼ í…œí”Œë¦¿ í•˜ë‹¨ì— ëª…ì‹œ (*í‘œì‹œë¡œ ì‹œì‘)
4. ì°¸ê³  í…œí”Œë¦¿ê³¼ ìœ ì‚¬í•œ í†¤ì•¤ë§¤ë„ˆ ìœ ì§€
5. ì¹´ì¹´ì˜¤í†¡ ì•Œë¦¼í†¡ ê·œì • ì¤€ìˆ˜
6. **ì ˆëŒ€ ë³€ìˆ˜ ëª©ë¡ì´ë‚˜ ë³€ìˆ˜ ì„¤ëª…ì„ í…œí”Œë¦¿ ë‚´ìš©ì— í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”**
7. **í…œí”Œë¦¿ì€ ì‹¤ì œ ë°œì†¡ë  ë©”ì‹œì§€ ë‚´ìš©ë§Œ í¬í•¨í•´ì•¼ í•©ë‹ˆë‹¤**

í…œí”Œë¦¿ë§Œ ìƒì„±í•´ì£¼ì„¸ìš”:
"""
            
            logger.debug("ğŸ¤– OpenAI API í˜¸ì¶œ ì¤‘... (ì°¸ê³  ê¸°ë°˜ ìƒì„±)")
            response = openai.chat.completions.create(
                model="gpt-4o-mini",
                messages=[
                    {"role": "system", "content": "ë‹¹ì‹ ì€ ì¹´ì¹´ì˜¤í†¡ ì•Œë¦¼í†¡ í…œí”Œë¦¿ ìƒì„± ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ìŠ¹ì¸ë°›ì€ í…œí”Œë¦¿ì„ ì°¸ê³ í•˜ì—¬ ê·œì •ì— ë§ëŠ” ìƒˆë¡œìš´ í…œí”Œë¦¿ì„ ìƒì„±í•©ë‹ˆë‹¤. ì ˆëŒ€ ë³€ìˆ˜ ëª©ë¡ì´ë‚˜ ë³€ìˆ˜ ì„¤ëª…ì„ í…œí”Œë¦¿ ë‚´ìš©ì— í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”."},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.3,
                max_tokens=1000
            )
            
            result = response.choices[0].message.content.strip()
            logger.info(f"âœ… ì°¸ê³  í…œí”Œë¦¿ ê¸°ë°˜ ìƒì„± ì™„ë£Œ: {len(result)}ì")
            logger.debug(f"[RESULT] {result[:100]}...")
            return result
            
        except Exception as e:
            logger.error(f"âŒ ì°¸ê³  í…œí”Œë¦¿ ê¸°ë°˜ ìƒì„± ì˜¤ë¥˜: {e}")
            logger.info("ğŸ”„ ê¸°ë³¸ ìƒì„± ë°©ì‹ìœ¼ë¡œ ì „í™˜...")
            return self.generate_new_template(request)
    
    def search_policy_guidelines(self, request: TemplateRequest) -> List[Dict]:
        """ì •ì±… ê°€ì´ë“œë¼ì¸ ê²€ìƒ‰"""
        try:
            guideline_collection = self.client.get_collection('policy_guidelines')
            
            # ì¹´í…Œê³ ë¦¬ì™€ ì‚¬ìš©ì‚¬ë¡€ë¡œ ê´€ë ¨ ì •ì±… ê²€ìƒ‰
            search_query = f"{request.category_main} {request.category_sub} {request.use_case}"
            
            results = guideline_collection.query(
                query_texts=[search_query],
                n_results=2,  # ì •ì±…ì€ ë„ˆë¬´ ë§ìœ¼ë©´ í˜¼ë€
                include=['documents', 'metadatas']
            )
            
            guidelines = []
            if results and results['documents'] and results['documents'][0]:
                for doc, metadata in zip(results['documents'][0], results['metadatas'][0]):
                    guidelines.append({
                        'text': doc,
                        'metadata': metadata
                    })
            
            return guidelines
            
        except Exception as e:
            print(f"ì •ì±… ê°€ì´ë“œë¼ì¸ ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
            return []

    def generate_template_with_policy_guidelines(self, request: TemplateRequest, guidelines: List[Dict]) -> str:
        """ì •ì±… ê°€ì´ë“œë¼ì¸ì„ ì°¸ê³ í•˜ì—¬ í…œí”Œë¦¿ ìƒì„±"""
        try:
            guidelines_text = "\n".join([g['text'] for g in guidelines])
            
            # í”„ë¡¬í”„íŠ¸ ë¹Œë” ì‚¬ìš©
            prompt_builder = PolicyGuidedTemplatePromptBuilder(request, guidelines_text)
            prompt = prompt_builder.build()
            
            response = openai.chat.completions.create(
                model="gpt-4o-mini",
                messages=[
                    {"role": "system", "content": "ë‹¹ì‹ ì€ ì¹´ì¹´ì˜¤í†¡ ì•Œë¦¼í†¡ ì •ì±… ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì •ì±… ê°€ì´ë“œë¼ì¸ì„ ì™„ë²½íˆ ì¤€ìˆ˜í•˜ëŠ” í…œí”Œë¦¿ë§Œ ìƒì„±í•©ë‹ˆë‹¤. ì ˆëŒ€ ë³€ìˆ˜ ëª©ë¡ì´ë‚˜ ë³€ìˆ˜ ì„¤ëª…ì„ í…œí”Œë¦¿ ë‚´ìš©ì— í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”."},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.2,  # ì •ì±… ì¤€ìˆ˜ë¥¼ ìœ„í•´ ë” ë‚®ì€ ì˜¨ë„
                max_tokens=1000
            )
            
            return response.choices[0].message.content.strip()
            
        except Exception as e:
            print(f"ì •ì±… ê¸°ë°˜ í…œí”Œë¦¿ ìƒì„± ì˜¤ë¥˜: {e}")
            return self.generate_new_template(request)

    def generate_new_template(self, request: TemplateRequest) -> str:
        """ì™„ì „íˆ ìƒˆë¡œìš´ í…œí”Œë¦¿ ìƒì„±"""
        try:
            # í”„ë¡¬í”„íŠ¸ ë¹Œë” ì‚¬ìš©
            prompt_builder = NewTemplatePromptBuilder(request)
            prompt = prompt_builder.build()
            
            response = openai.chat.completions.create(
                model="gpt-4o-mini",
                messages=[
                    {"role": "system", "content": "ë‹¹ì‹ ì€ ì¹´ì¹´ì˜¤í†¡ ì•Œë¦¼í†¡ í…œí”Œë¦¿ ìƒì„± ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì•Œë¦¼í†¡ ê·œì •ì„ ì¤€ìˆ˜í•˜ëŠ” ì •ë³´ì„±/ì•ˆë‚´ì„± í…œí”Œë¦¿ì„ ìƒì„±í•©ë‹ˆë‹¤. ì ˆëŒ€ ë³€ìˆ˜ ëª©ë¡ì´ë‚˜ ë³€ìˆ˜ ì„¤ëª…ì„ í…œí”Œë¦¿ ë‚´ìš©ì— í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”."},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.5,
                max_tokens=1000
            )
            
            return response.choices[0].message.content.strip()
            
        except Exception as e:
            print(f"ìƒˆ í…œí”Œë¦¿ ìƒì„± ì˜¤ë¥˜: {e}")
            return "í…œí”Œë¦¿ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
    
    def extract_variables(self, template_text: str) -> List[str]:
        """í…œí”Œë¦¿ì—ì„œ ë³€ìˆ˜ ì¶”ì¶œ"""
        import re
        variables = re.findall(r'#\{([^}]+)\}', template_text)
        return list(set(variables))  # ì¤‘ë³µ ì œê±°
    
    def generate_title(self, request: TemplateRequest, template_text: str) -> str:
        """í…œí”Œë¦¿ ì œëª© ìƒì„±"""
        try:
            # í”„ë¡¬í”„íŠ¸ ë¹Œë” ì‚¬ìš©
            prompt_builder = TemplateTitlePromptBuilder(request, template_text)
            prompt = prompt_builder.build()
            
            response = openai.chat.completions.create(
                model="gpt-4o-mini",
                messages=[
                    {"role": "system", "content": "ê°„ë‹¨í•˜ê³  ëª…í™•í•œ í…œí”Œë¦¿ ì œëª©ì„ ìƒì„±í•©ë‹ˆë‹¤."},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.3,
                max_tokens=50
            )
            
            return response.choices[0].message.content.strip()
            
        except Exception as e:
            print(f"ì œëª© ìƒì„± ì˜¤ë¥˜: {e}")
            return request.label or "í…œí”Œë¦¿ ì•ˆë‚´"
    
    
    def generate_template(self, request: TemplateRequest) -> TemplateResponse:
        """
        ë©”ì¸ í…œí”Œë¦¿ ìƒì„± í•¨ìˆ˜ (ìš”êµ¬ì‚¬í•­ì— ë§ëŠ” 4ë‹¨ê³„ íë¦„)
        1. ë©”ì‹œì§€ ìœ í˜• íŒë‹¨ (ì´ë¯¸ requestì— í¬í•¨ë¨)
        2. ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜ (ì´ë¯¸ requestì— í¬í•¨ë¨)
        3. RAG ê²€ìƒ‰ (Top 3 â†’ 2ê°œ ì„ íƒ)
        4. ìµœì¢… í…œí”Œë¦¿ ìƒì„±
        """
        try:
            print("ğŸš€ í…œí”Œë¦¿ ìƒì„± íŒŒì´í”„ë¼ì¸ ì‹œì‘")
            
            # 1ë‹¨ê³„: ë©”ì‹œì§€ ìœ í˜• íŒë‹¨ (ì´ë¯¸ requestì— í¬í•¨ë¨)
            print(f"1ï¸âƒ£ ë©”ì‹œì§€ ìœ í˜•: {request.type}")
            
            # 2ë‹¨ê³„: ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜ (ì´ë¯¸ requestì— í¬í•¨ë¨)
            print(f"2ï¸âƒ£ ì¹´í…Œê³ ë¦¬: {request.category_main} > {request.category_sub}")
            
            # 3ë‹¨ê³„: RAG ê²€ìƒ‰ (Top 3 â†’ 2ê°œ ì„ íƒ)
            print("3ï¸âƒ£ RAG ê²€ìƒ‰ ì¤‘...")
            similar_templates, max_similarity = self.search_similar_templates(
                request.user_text,
                request.category_main,
                request.category_sub,
                top_k=3,
                select_count=2
            )
            print(f"âœ… ì°¸ê³  í…œí”Œë¦¿ {len(similar_templates)}ê°œ ì„ íƒ")
            
            # 4ë‹¨ê³„: ìµœì¢… í…œí”Œë¦¿ ìƒì„±
            print("4ï¸âƒ£ ìµœì¢… í…œí”Œë¦¿ ìƒì„± ì¤‘...")
            reference_template_ids = []
            generation_method = "new_creation"
            
            if similar_templates:
                # ì°¸ê³  í…œí”Œë¦¿ 2ê°œë¥¼ í™œìš©í•œ ìƒì„±
                template_text = self.generate_template_with_reference(request, similar_templates)
                reference_template_ids = [template['id'] for template in similar_templates]
                generation_method = "reference_based"
            else:
                # ì°¸ê³  í…œí”Œë¦¿ì´ ì—†ìœ¼ë©´ ì •ì±… ê°€ì´ë“œë¼ì¸ ê¸°ë°˜ ìƒì„±
                guidelines = self.search_policy_guidelines(request)
                if guidelines:
                    template_text = self.generate_template_with_policy_guidelines(request, guidelines)
                    generation_method = "policy_guided"
                else:
                    # ê°€ì´ë“œë¼ì¸ë„ ì—†ìœ¼ë©´ ê¸°ë³¸ ìƒì„±
                    template_text = self.generate_new_template(request)
                    generation_method = "new_creation"
            
            # í…œí”Œë¦¿ ì œëª© ìƒì„±
            template_title = self.generate_title(request, template_text)
            
            # ë³€ìˆ˜ ì¶”ì¶œ
            variables_detected = self.extract_variables(template_text)
            
            print("âœ… ìµœì¢… í…œí”Œë¦¿ ìƒì„± ì™„ë£Œ")
            
            # ì‘ë‹µ ìƒì„±
            return TemplateResponse(
                template_text=template_text,
                template_title=template_title,
                generation_method=generation_method,
                reference_template_id=reference_template_ids[0] if reference_template_ids else None,
                metadata={
                    "request_info": request.dict(),
                    "reference_templates": similar_templates,
                    "generation_flow": "4ë‹¨ê³„ íŒŒì´í”„ë¼ì¸ ì™„ë£Œ",
                    "variables_detected": variables_detected  # ë©”íƒ€ë°ì´í„°ì— í¬í•¨
                }
            )
            
        except Exception as e:
            print(f"í…œí”Œë¦¿ ìƒì„± ì˜¤ë¥˜: {e}")
            raise HTTPException(status_code=500, detail=f"í…œí”Œë¦¿ ìƒì„± ì‹¤íŒ¨: {str(e)}")

# FastAPI ì•± ìƒì„±
app = FastAPI(title="ì¹´ì¹´ì˜¤í†¡ í…œí”Œë¦¿ ìƒì„± API", version="1.0.0")
generator = TemplateGenerator()

@app.post("/generate-template", response_model=TemplateResponse)
async def generate_template_endpoint(request: TemplateRequest):
    """í…œí”Œë¦¿ ìƒì„± API ì—”ë“œí¬ì¸íŠ¸"""
    return generator.generate_template(request)

@app.get("/health")
async def health_check():
    """í—¬ìŠ¤ ì²´í¬"""
    return {"status": "healthy", "message": "Template Generator API is running"}

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000, reload=True)
