from dotenv import load_dotenv
# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from typing import List, Optional
import os
from routers import ai_routes
# ë¡œê¹… ì•ˆë˜ì„œ ë„£ìŒ
# import logging
#
# logging.basicConfig(
#     level=logging.DEBUG,  # ë˜ëŠ” INFO
#     format="%(asctime)s | %(name)s | %(levelname)s | %(message)s",
#     datefmt="%Y-%m-%d %H:%M:%S"
# )
#
# logger = logging.getLogger(__name__)
# logger.setLevel(logging.DEBUG)

app = FastAPI(
    title="AI Service API",
    description="FastAPI + ChromaDB + OpenAI + Hugging Face AI ì„œë¹„ìŠ¤\n\ní¬í•¨ëœ ì„œë¹„ìŠ¤:\n- ê¸°ë³¸ AI ì„œë¹„ìŠ¤\n- ì•Œë¦¼í†¡ í…œí”Œë¦¿ ê²€ì¦ ì‹œìŠ¤í…œ",
    version="1.0.0"
)

# CORS ì„¤ì •
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ë¼ìš°í„° ë“±ë¡
app.include_router(ai_routes.router)

# ì•Œë¦¼í†¡ ê²€ì¦ ë¼ìš°í„° ì¶”ê°€
try:
    from routers import alimtalk_routes
    app.include_router(alimtalk_routes.router)
    print("âœ… ì•Œë¦¼í†¡ ê²€ì¦ ë¼ìš°í„° ë“±ë¡ ì™„ë£Œ")
    
    # ì•Œë¦¼í†¡ ì„œë¹„ìŠ¤ ì´ˆê¸°í™”
    @app.on_event("startup")
    async def initialize_alimtalk():
        """ì•Œë¦¼í†¡ ì„œë¹„ìŠ¤ ì´ˆê¸°í™”"""
        try:
            print("ğŸ”§ ì•Œë¦¼í†¡ ê²€ì¦ ì„œë¹„ìŠ¤ ì´ˆê¸°í™” ì¤‘...")
            await alimtalk_routes.validation_service.initialize()
            print("âœ… ì•Œë¦¼í†¡ ê²€ì¦ ì„œë¹„ìŠ¤ ì´ˆê¸°í™” ì™„ë£Œ!")
        except Exception as e:
            print(f"âŒ ì•Œë¦¼í†¡ ì„œë¹„ìŠ¤ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            
except ImportError as e:
    print(f"âš ï¸ ì•Œë¦¼í†¡ ê²€ì¦ ë¼ìš°í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
except Exception as e:
    print(f"âŒ ì•Œë¦¼í†¡ ê²€ì¦ ë¼ìš°í„° ë“±ë¡ ì‹¤íŒ¨: {e}")

# í…œí”Œë¦¿ ë¼ìš°í„° ì¶”ê°€ (ì¡´ì¬í•˜ì§€ ì•Šìœ¼ë¯€ë¡œ ì œê±°)
# from routers import template_routes
# app.include_router(template_routes.router)

# Pydantic ëª¨ë¸
class ChatRequest(BaseModel):
    message: str
    model: Optional[str] = "gpt-4o-mini"

class ChatResponse(BaseModel):
    response: str
    model: str

class DocumentRequest(BaseModel):
    content: str
    metadata: Optional[dict] = None

class SearchRequest(BaseModel):
    query: str
    n_results: Optional[int] = 5

# ê¸°ë³¸ ë¼ìš°íŠ¸
@app.get("/")
async def root():
    return {"message": "AI Service is running!"}

@app.get("/health")
async def health_check():
    return {"status": "healthy"}

# ì±„íŒ… ì—”ë“œí¬ì¸íŠ¸
@app.post("/chat", response_model=ChatResponse)
async def chat(request: ChatRequest):
    try:
        # OpenAI API í˜¸ì¶œ (ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” OpenAI í´ë¼ì´ì–¸íŠ¸ ì‚¬ìš©)
        response = f"AI ì‘ë‹µ: {request.message}"
        return ChatResponse(response=response, model=request.model)
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

# ë¬¸ì„œ ì €ì¥ ì—”ë“œí¬ì¸íŠ¸
@app.post("/documents")
async def add_document(request: DocumentRequest):
    try:
        # ChromaDBì— ë¬¸ì„œ ì €ì¥ (ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” ChromaDB í´ë¼ì´ì–¸íŠ¸ ì‚¬ìš©)
        return {"message": "Document added successfully", "content": request.content}
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

# ê²€ìƒ‰ ì—”ë“œí¬ì¸íŠ¸
@app.post("/search")
async def search_documents(request: SearchRequest):
    try:
        # ChromaDBì—ì„œ ê²€ìƒ‰ (ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” ChromaDB í´ë¼ì´ì–¸íŠ¸ ì‚¬ìš©)
        results = [f"ê²€ìƒ‰ ê²°ê³¼ {i+1}: {request.query}" for i in range(request.n_results)]
        return {"query": request.query, "results": results}
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)
